---
layout : post
title : 쿠다ML기초 3주차
categories : 쿠다ML 기초
---
# RNN과 CNN을 사용한 시퀀스 처리
## 15.1 순환 뉴런과 순환 층
순환 신경망 (RNN) : 입력 층에서 출력 층 방향으로 흐르거나, 뒤쪽으로 순환하는 연결도 가능한 신경망

![image](https://github.com/user-attachments/assets/6776e2e7-5f71-45b3-af93-81bb60224c57)

1. 각 순환 뉴런은 입력을 위한 가중치와 이전 타임 스텝의 출력을 위한 가중치를 가짐 
2. 각 타임 스텝마다 X(t)와 이전 타임 스텝의 출력인 y(t-1)을 입력 받음 (첫 번째 타임스텝은 0으로 설정)

![image](https://github.com/user-attachments/assets/7b9dc5fe-8ae1-4718-b654-1345b6b1db75)

### 15.1.1 메모리 셀

*메모리 셀의 개념*

→ 순환 신경망(RNN)의 기본 요소로, 일정한 메모리 형태를 가지고 있음.

→ 이전 타임스텝의 모든 입력에 대한 함수로 표현될 수 있음.

→ 하나의 순환 뉴런 또는 순환 뉴런 층(스택) 으로 구성됨.

*메모리 셀의 역할*

→ 단기 패턴 학습:

보통 10 스텝 정도의 길이에 대한 패턴을 학습 가능.

문제의 특성에 따라 다르게 적용될 수 있음.

장기 패턴 학습:

10 스텝 이상의 긴 패턴도 학습할 수 있는 더욱 강력한 셀 구조가 필요함.

*셀의 상태 업데이트*

일반적으로 셀의 상태 ℎ(𝑡)는 현재 타임스텝의 입력과 이전 타임스텝의 상태를 반영하여 결정됨.

수식으로 표현하면:

![image](https://github.com/user-attachments/assets/6bedf92a-0386-4bdc-878a-0d7d0c9febfd)

### 15.1.2 입력과 출력 시퀀스
RNN은 입력 시퀀스를 받아서 출력 시퀀스를 생성하는 모델 (입력과 출력의 관계에 따라 다양한 구조의 네트워크가 존재)

|네트워크 유형|설명|예시|
|---|---|---|
|시퀀스-투-시퀀스|입력과 출력이 모두 시퀀스|전력 소비량 예측|
|시퀀스-투-벡터|입력은 시퀀스, 출력은 고정 벡터|감정 분석 (긍/부정)|
|벡터-투-시퀀스|입력은 벡터, 출력은 시퀀스|이미지 → 문장 설명|
|인코더-디코더|입력을 인코딩 후 디코딩하여 변환|기계 번역|

![image](https://github.com/user-attachments/assets/f4b619a7-a9b2-4d4b-885b-ea368897c7ab)

※ 인코더-디코더 이중 단계 모델에서 디코더의 초기 입력값을 0으로 설정해도, 무엇을 출력해야 할지 힌트가 필요하므로, 인코더의 마지막 은닉 상태 h(T) 를 디코더의 초기 은닉 상태로 사용

## 15.2 RNN 훈련하기
BPTT : RNN을 훈련하기 위한 기법으로, 타임 스텝으로 네트워크를 펼치고 보통의 역전파를 사용하는 기법

![image](https://github.com/user-attachments/assets/2ae10abe-52d8-4c10-be86-a80f3f1e2597)

→ 네트워크가 시간에 따라 펼쳐진 형태로 존재

1. 순전파 (Forward Pass)
→ 입력 X를 각 타임스텝에서 처리하여 은닉 상태를 업테이트
→ 마지막 타임스텝까지 도달하면 예측 Y가 생성됨
2. 손실함수 𝐿 계산
→ 출력 Y와 실제 값 Y 비교하여 손실 계산 (그림에서는 L(Y2,Y3,Y4) 손실 계산됨)
3. 역전파 (Backward Pass)
→ 계산된 손실을 시간을 거슬러서 각 타임스텝의 가중치에 대해 미분 & 모든 가중치 W와 b (이하 파라미터)를 업데이트

※ 케라스가 싹 다 처리해줌

## 15.3 시계열 예측하기
시계열 데이터 로드 및 정제
```python
import pandas as pd
from pathlib import Path

path = Path ('datasets/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv')
df = pd.read_csv (path, parse_dates["service_date"])
df.columns = ['date', 'day_type','bus','rail','total'] # 짧은 이름
df = df.drop('total', axis = 1) # total은 단순히 bus+rail이므로 제거
df = df.drop_duplicates () #중복 월 삭제 (2011-10과 2014-07)
```
단순 예측 및 결과 시각화

단순 에측 : 과거 정보(가장 최근값)를 이용하여 미래 값을 직접 예측하는 방 (패턴이 매우 강력할 때)

```python
diff_7 = df[['bus,'rail']].diff(7)['2019-03' : '2019-05']

fig, axs = plt.subplots(2,1,sharex = True, figsize = (8,5))
df.plot(ax=axs[0], legend = False, marker = '.') #원본 시계열
df.shift(7).plot(ax=axs[0], grid = True, legend = False, linestyle = ':') # 지연된 시계열
diff_7.plot(ax=axs[1], grid = True, marker = '.') # 7일 간의 차이
plt.show()
```

자기상관 : 시계열이 시간이 지연된 자기자신과 상관관계를 가지는 것

MAE와 MAPE를 사용한 예측 오류 평가
```python
# MAE 
diff_7.abs().mean()
```
MAE (평균 절대 오차) : 예측값과 실제값의 차이를 평균낸 값 (단위가 데이터와 동일)

MAE가 크다는 것은 오차가 크다는 의미!

```python
targets = df[['bus','rail']]['2019-03':'2019-05']
(diff_7/targets).abs().mean()
```
MAPE (평균 절대 비율 오차) : 예측값과 실제값의 차이를 실제값으로 나눈 비율 평균 (비율로 나타내므로 단위에 영향 X)

차분 : 시계열 데이터에서 트렌드와 계절성을 제거하기 위해 사용되는 기법 (각각의 시점에서 이전 시점과의 차이를 계산하여 새로운 시계열 생성) → 시간이 지나도 평균과 분산이 일정한 **정상 시계열** 생성 가능 (변동 폭 일정한 패턴으로 변화)

예측에서 차분이 왜 중요한가? 

트렌드를 고려하여 매년 평균적으로 감소하는 값 (책의 승객 이용 데이터 예시)을 반영하면 예측 정확도를 높일 수 있음

☆ 차분을 사용하면 단기 패턴을 쉽게 포착할 수 있고, 트렌드를 고려하면 장기적인 예측 성능 개선 가능








