---
layout : post
title : 쿠다ML기초 3주차
categories : 쿠다ML 기초
---
# RNN과 CNN을 사용한 시퀀스 처리
## 15.1 순환 뉴런과 순환 층
순환 신경망 (RNN) : 입력 층에서 출력 층 방향으로 흐르거나, 뒤쪽으로 순환하는 연결도 가능한 신경망

![image](https://github.com/user-attachments/assets/6776e2e7-5f71-45b3-af93-81bb60224c57)

1. 각 순환 뉴런은 입력을 위한 가중치와 이전 타임 스텝의 출력을 위한 가중치를 가짐 
2. 각 타임 스텝마다 X(t)와 이전 타임 스텝의 출력인 y(t-1)을 입력 받음 (첫 번째 타임스텝은 0으로 설정)

![image](https://github.com/user-attachments/assets/7b9dc5fe-8ae1-4718-b654-1345b6b1db75)

### 15.1.1 메모리 셀

*메모리 셀의 개념*

→ 순환 신경망(RNN)의 기본 요소로, 일정한 메모리 형태를 가지고 있음.

→ 이전 타임스텝의 모든 입력에 대한 함수로 표현될 수 있음.

→ 하나의 순환 뉴런 또는 순환 뉴런 층(스택) 으로 구성됨.

*메모리 셀의 역할*

→ 단기 패턴 학습:

보통 10 스텝 정도의 길이에 대한 패턴을 학습 가능.

문제의 특성에 따라 다르게 적용될 수 있음.

장기 패턴 학습:

10 스텝 이상의 긴 패턴도 학습할 수 있는 더욱 강력한 셀 구조가 필요함.

*셀의 상태 업데이트*

일반적으로 셀의 상태 ℎ(𝑡)는 현재 타임스텝의 입력과 이전 타임스텝의 상태를 반영하여 결정됨.

수식으로 표현하면:

![image](https://github.com/user-attachments/assets/6bedf92a-0386-4bdc-878a-0d7d0c9febfd)

### 15.1.2 입력과 출력 시퀀스
RNN은 입력 시퀀스를 받아서 출력 시퀀스를 생성하는 모델 (입력과 출력의 관계에 따라 다양한 구조의 네트워크가 존재)

|네트워크 유형|설명|예시|
|---|---|---|
|시퀀스-투-시퀀스|입력과 출력이 모두 시퀀스|전력 소비량 예측|
|시퀀스-투-벡터|입력은 시퀀스, 출력은 고정 벡터|감정 분석 (긍/부정)|
|벡터-투-시퀀스|입력은 벡터, 출력은 시퀀스|이미지 → 문장 설명|
|인코더-디코더|입력을 인코딩 후 디코딩하여 변환|기계 번역|

![image](https://github.com/user-attachments/assets/f4b619a7-a9b2-4d4b-885b-ea368897c7ab)

※ 인코더-디코더 이중 단계 모델에서 디코더의 초기 입력값을 0으로 설정해도, 무엇을 출력해야 할지 힌트가 필요하므로, 인코더의 마지막 은닉 상태 h(T) 를 디코더의 초기 은닉 상태로 사용

## 15.2 RNN 훈련하기
BPTT : RNN을 훈련하기 위한 기법으로, 타임 스텝으로 네트워크를 펼치고 보통의 역전파를 사용하는 기법

![image](https://github.com/user-attachments/assets/2ae10abe-52d8-4c10-be86-a80f3f1e2597)

→ 네트워크가 시간에 따라 펼쳐진 형태로 존재

1. 순전파 (Forward Pass)
→ 입력 X를 각 타임스텝에서 처리하여 은닉 상태를 업테이트
→ 마지막 타임스텝까지 도달하면 예측 Y가 생성됨
2. 손실함수 𝐿 계산
→ 출력 Y와 실제 값 Y 비교하여 손실 계산 (그림에서는 L(Y2,Y3,Y4) 손실 계산됨)
3. 역전파 (Backward Pass)
→ 계산된 손실을 시간을 거슬러서 각 타임스텝의 가중치에 대해 미분 & 모든 가중치 W와 b (이하 파라미터)를 업데이트

※ 케라스가 싹 다 처리해줌

## 15.3 시계열 예측하기
시계열 데이터 로드 및 정제
```python
import pandas as pd
from pathlib import Path

path = Path ('datasets/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv')
df = pd.read_csv (path, parse_dates["service_date"])
df.columns = ['date', 'day_type','bus','rail','total'] # 짧은 이름
df = df.drop('total', axis = 1) # total은 단순히 bus+rail이므로 제거
df = df.drop_duplicates () #중복 월 삭제 (2011-10과 2014-07)
```
단순 예측 및 결과 시각화

단순 에측 : 과거 정보(가장 최근값)를 이용하여 미래 값을 직접 예측하는 방법 (패턴이 매우 강력할 때)

```python
diff_7 = df[['bus,'rail']].diff(7)['2019-03' : '2019-05']

fig, axs = plt.subplots(2,1,sharex = True, figsize = (8,5))
df.plot(ax=axs[0], legend = False, marker = '.') #원본 시계열
df.shift(7).plot(ax=axs[0], grid = True, legend = False, linestyle = ':') # 지연된 시계열
diff_7.plot(ax=axs[1], grid = True, marker = '.') # 7일 간의 차이
plt.show()
```

자기상관 : 시계열이 시간이 지연된 자기자신과 상관관계를 가지는 것

MAE와 MAPE를 사용한 예측 오류 평가
```python
# MAE 
diff_7.abs().mean()
```
MAE (평균 절대 오차) : 예측값과 실제값의 차이를 평균낸 값 (단위가 데이터와 동일)

MAE가 크다는 것은 오차가 크다는 의미!

```python
targets = df[['bus','rail']]['2019-03':'2019-05']
(diff_7/targets).abs().mean()
```
MAPE (평균 절대 비율 오차) : 예측값과 실제값의 차이를 실제값으로 나눈 비율 평균 (비율로 나타내므로 단위에 영향 X)

연간 계절성이 나타나는지에 대해서 그래프를 생성하고 분석해보자.

```python
period = slice('2001','2019')
df_monthly = df.resample('M').mean() #월 평균 계산
rolling_average_12_months = df_monthly[period].rolling(window=12).mean()

fig, ax = plt.subplots(figsize = (8,4))
df_monthly[period].plot(ax=ax, marker='.')
rolling_average_12_months.plot(ax=ax, grid = True, legend = False)
plt.show()
```
그리고 차분을 살펴보자.
```python
df_monthly.diff(12)[period].plot(grid=True, marker = '/', figsize(8,3))
plt.show()
```
![image](https://github.com/user-attachments/assets/ec8b561b-129e-43e5-b26d-9bedf46490f1)

![image](https://github.com/user-attachments/assets/6b7b99be-db80-457d-84af-75e4fc7f39e8)

차분 : 시계열 데이터에서 트렌드와 계절성을 제거하기 위해 사용되는 기법 (각각의 시점에서 이전 시점과의 차이를 계산하여 새로운 시계열 생성) → 시간이 지나도 평균과 분산이 일정한 **정상 시계열** 생성 가능 (변동 폭 일정한 패턴으로 변화)

예측에서 차분이 왜 중요한가? 

트렌드를 고려하여 매년 평균적으로 감소하는 값 (책의 승객 이용 데이터 예시)을 반영하면 예측 정확도를 높일 수 있음

☆ 차분을 사용하면 단기 패턴을 쉽게 포착할 수 있고, 트렌드를 고려하면 장기적인 예측 성능 개선 가능

### 15.3.1 ARMA 모델

**ARMA (자기 회귀 이동 평균)** = AR (자기 회귀) + MA (이동 평균) : 지연된 값의 간단한 가중치 합 계산 + 이동 평균 합 → 예측 수정

※ 마지막 몇 개의 예측 오차의 가중치 합 사용하여 이동 평균 계산

***이 모델은 정상 시계열을 가정한다!***

즉, 평균과 분산이 시간이 지나도 일정한 시계열 데이터를 가정한다. but, 실제 데이터는 비정상 시계열이 대부분.

→ 차분 활용하여 정상 시계열로 변환.

차분 : 미분의 근사값과 유사. 각 타임 스텝에서 시계열의 기울기 (연속적 데이터일 때)

(원본 시계열이 d차 방정식 형태 트렌드를 가질 때 : 연속적인 d번의 차분을 수행하여 시계열의 d차 도함수를 근사. d차 다항식 트렌드 제거 가능. 여기서 d를 **누적 차수**라고 함)

**ARIMA (자기 회귀 누적 이동 평균)** = AR + I (차분) + MA : d번의 차분을 수행하여 시계열을 정상 상태로 만들고, 일반적인 ARMA 모델 적용 → 차분으로 뺐던 값을 다시 더함 (원래 시계열 예측값. 원래 스케일로 복원)

**SARIMA (계절성 ARIMA)** = 주어진 빈도에 대한 계절 항을 추가로 모델링하는 ARIMA의 유형 : 총 7개의 하이퍼파라미터를 가짐

SARIMA 모델의 하이퍼파라미터 살펴보기

SARIMA 모델의 하이퍼파라미터는 ARIMA 모델을 위한 p,d,q 하이퍼파라미터, 계절성 패턴을 모델링 하기 위한 P,D,Q 하이퍼파라미터, 계절성 패턴의 간격인 s가 존재한다. (계절성 패턴은 단위별로 상이함)

|하이퍼파라미터|설명|
|---|---|
|p|자기회귀(AR)차수|
|d|차분 횟수|
|q|이동평균(MA) 차수|
|P|계절적 자기회귀 차수|
|D|계절적 차분 횟수|
|Q|계절적 이동평균 차수|
|m|계절 주기|

ARIMA 클래스의 statsmodels 라이브러리를 활용한 SARIMA 모델 적용
```python
from statsmodels.tsa.arima.model import ARIMA

origin, today = '2019-01-01', '2019-05-31'
rail_series = df.loc[origin:today]['rail'].asfreq('D') #여기서 D를 통해 빈도를 일자별로 설정
model = ARIMA (rail_series, order = (1,0,0), seasonal_order = (0,1,1,7))
model = model.fit()
y_pred = model.forecast ()
# 위 코드는 예측력이 좋지 않다. 따라서 3,4,5월의 모든 날에 대한 예측을 만들고 전체 기간에 대한 MAE를 계산하겠다.
origin, start_date, end_date = '2019-01-01', '2019-03-01', '2019-05-31'
time_period = pd.date_range (start_date, end_date)
rail_series = df.loc[origin:end_date]['rail'].asfreq('D')
y_preds = []
for today in time_period.shift(-1) :
  model = ARIMA (rail_series[origin:today], order = (1,0,0), seasonal_order = (0,1,1,7)) # today까지 데이터로 훈련
  model = model.fit()
  y_pred = model.forecast()[0]
  y_preds.append(y_pred)

y_preds = pd.Series (y_preds, index = time_period)
mae = (y_preds - rail_series[time_period].abs().mean()
결과를 표시하지 않았지만 성능이 높아졌다는 것을 확인할 수 있다.
```

SARIMA 모델의 하이퍼파라미터를 선택하는 방법

가장 쉽고 시작하기 좋은 방법 : 단순 그리드 서치 (여러 조합 실험, 하이퍼파라미터 값만 바꾸면서 코드 실행)










