---
layout : posts
title : 쿠다 ML 심화 6주차
categories : 쿠다 ML 심화
---
# 13. 텍스트 유사성 측정
본 장에서는 두 텍스트의 유사도를 측정하는 기본적인 NLP 문제에 대하여 다루고자 한다.
## 13.1 간단한 텍스트 비교
3개의 텍스트가 주어졌다고 가정할 때, 텍스트 간 차이를 정량화 해야 함
```python
text1 = 'She sells seashells by the seashore.'
text2 = '"Seashells! The seashells are on sale! By the seashore."'
text3 = 'She sells 3 seashells to John, who lives by the lake.'
```

**자카드 유사도** : 두 텍스트의 유사성을 평가하는 간단한 지표 (전체 단어 수에 대한 교집합 비율)

** 자카드 유사도의 작동 방식** :
1. 두 텍스트가 주어졌을 때 각 텍스트에서 단어 리스트 추출
2. 텍스트 간 공유되는 고유 단어 수를 셈
3. 공유 단어 수를 두 텍스트의 총 고유 단어 수로 나눔

![image](https://github.com/user-attachments/assets/067336d0-8919-4465-9b35-6ec04fcf3ead)

※ 그림에서 자카드 유사도 : 4/9

### 13.1.1 자카드 유사도 탐색
자카드 유사도가 텍스트 유사성을 합리적으로 측정하는 척도인 이유

▶ 텍스트 간 겹치는 단어와 그렇지 않은 단어 함께 고려

▶ 항상 0과 1 사이로 표현됨 + 해석 용이 (0 : 공유 단어 無 | 0.5 : 공유 단어 半 | 1 : 모든 단어 공유)

### 13.1.2 단어를 숫자 값으로 바꾸기
**텍스트의 벡터화** : 딕셔너리에 각 고유 단어 정보 저장 후, 어휘가 주어지면 1차원 숫자 배열인 벡터로 변환 (해당 단어 텍스트가 존재하면 벡터느 1로, 존재하지 않으면 0으로 변환됨)

벡터의 내적을 이용하여 공유하는 단어 수를 구할 수 있음 → 벡터 연산만으로 자카드 유사도를 계산할 수 있음
```python
assert vector.dot(vector2) == shared_word_count
assert vector @ vector2 == shared_word_count
```
이와 같이 벡터화된 텍스트로 자카드 유사도를 구현한 것 : **타니모토 유사도**

▶ 이진 벡터 또는 비이진 벡터 ([5,2],[5,3])을 비교하여 유사도를 측정

## 13.2 단어 수를 사용하여 텍스트 벡터화하기
텍스트 상황 설정

텍스트 A: "오리" 61회, "거위" 2회 등장 → 벡터 A = [61, 2]

텍스트 B: "오리" 1회, "거위" 71회 등장 → 벡터 B = [1, 71]

이전의 이진 벡터는 단지 '등장 여부'만 판단하기 때문에 두 텍스트 모두 "오리", "거위"가 포함되므로 유사도가 1에 가까워짐

***하지만, 실제로 등장 빈도 다름***

```python
similarity = tanimoto_similarity(np.array([61, 2]), np.array([1, 71]))
print(f"텍스트 간 유사도는 약 {similarity:.3f}입니다")
```
각 인덱스에 등장 빈도 값을 할당하여 유사도를 측정할 수 있음

→ 단어 수 벡터 생성 (용어 빈도 벡터 또는 TF 벡터)

※ TF 벡터화는 두 텍스트의 선호도를 더욱 뚜렷하게 만든다.

**TF 벡터의 장점과 한계**

*장점* : 단어 수 차이에 민감하기에 향상된 비교 결과 제공 

*단점* : 길이가 다른 텍스트 비교 시 불리

### 13.2.1 정규화로 TF 벡터 유사도 개선하기
텍스트 사용 예시 

제목 A : "Pepperoni Pizza! Pepperoni Pizza! Pepperoni Pizza!"

제목 B ; "Pepperoni"

검색엔진에 쿼리를 입력 → 이 쿼리를 TF 벡터로 변환하고, 저장된 문서들의 제목과 유사도 비교 (관련도 계산)

문제점 : TF 벡터의 크기 (스케일)에 따른 유사도 왜곡 발생

이유 → 제목 A의 단어 등장 횟수가 많아 Tanimoto 유사도에서는 오히려 제목 B의 점수가 더 높음 (Tanimoto 유사도는 벡터의 ‘방향’보다 ‘크기’에 더 민감하기 때문)

제목A(3,3)의 벡터는 크기가 커서 내적이 높지만, 분모가 더 커져서 유사도는 낮아짐

제목B(1,1)는 내적이 작지만 분모도 작아서 비율이 더 높음

![image](https://github.com/user-attachments/assets/d55e7d92-84e5-48f0-9b49-a5142727dbef)

해결 방법 : 정규화 (크기 통일)

크기 차이(스케일 차이)를 없애기 위해 나누어서 크기 제거

![image](https://github.com/user-attachments/assets/aebd40c9-aa7c-41e2-bf9e-09a41b38bee2)

(여기서 쿼리 벡터가 A의 정규화된 벡터를 의미)

이처럼 크기를 1로 정규화 시 단어의 수 차이는 중요해지지 않음 (=단위벡터이므로 방향에 따라서만 결정)











