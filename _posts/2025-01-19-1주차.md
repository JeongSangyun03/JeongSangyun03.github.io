---
layout: post
title:  "01. 분류"
date:   2025-01-19
categories: ['ML기초']
---
# 쿠다 ML 기초 1주차

이 장에서는 분류 시스템을 집중적으로 다루어 보려고 한다. 

**(사실대로 말하면 사이킷런에 있는 데이터를 불러올 수 없어서 교재에 나온 코드를 보완하여 정리하려고 한다.)**
```python
import sys
assert sys.version_info >= (3, 7)
import matplotlib.pyplot as plt
plt.rc('font', size=14)
plt.rc('axes', labelsize=14, titlesize=14)
plt.rc('legend', fontsize=14)
plt.rc('xtick', labelsize=10)
plt.rc('ytick', labelsize=10)
from pathlib import Path

IMAGES_PATH = Path() / "images" / "classification"
IMAGES_PATH.mkdir(parents=True, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension="png", resolution=300):
    path = IMAGES_PATH / f"{fig_id}.{fig_extension}"
    #images/classification 폴더가 없다면 이 폴더를 만들고 고해상도 이미지 저장을 위해 노트북에서 사용할 save_fig() 함수를 정의한다.
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)
```

## 3.1 MNIST

MNIST 데이터셋이란 고등학생과 미국 인구 조사국 직원들이 손으로 쓴 70000개의 작은 숫자 이미지이다. 각 이미지에는 어떤 숫자를 나타내는지 레이블이 되어있고, 머신러닝 학습을 위한 유용한 데이터로 활용된다.
이는 사이킷런에서 제공하는 여러 헬퍼 함수를 사용하여 잘 알려진 데이터셋을 내려받을 수 있다.
다음은 OpenML.org에서 MNIST 데이터셋을 내려받는 코드이다.

```python
import tensorflow as tf
import numpy as np
#사이킷런에 있는 데이터 대신 텐서플로우의 숫자 분류 데이터를 쓰려고 한다.
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

x_all = (np.concatenate([x_train, x_test], axis=0))
y = np.concatenate([y_train, y_test], axis=0)

X = x_all.reshape(x_all.shape[0], -1)

print("전체 데이터 (2D 변환) 크기:", X.shape)
print("전체 라벨 크기: ", y.shape)
```

X와 y의 데이터 배열을 살펴보면 array([0., 0., ..., 0., 0., 0.], ...)과 같은 형태가 나온다. 이게 뭘 의미할까?

각 이미지에는 784개의 특성이 있다. 이미지가 28X28 픽셀이기 때문이다.

각각의 특성은 단순히 0(흰색)부터 255(검은색)까지의 픽셀 강도를 나타낸다.

X[0] 데이터인 숫자 5를 출력해보자.

```python
import matplotlib.pyplot as plt

def plot_digit(image_data):
    image = image_data.reshape(28, 28)
    plt.imshow(image, cmap="binary")
    plt.axis("off")

some_digit = X[0]
plot_digit(some_digit)
save_fig("some_digit_plot")  # 추가 코드
plt.show()
```

![some_digit_plot](https://github.com/user-attachments/assets/61d1f72c-db35-4df6-b0c3-3534745d6c58)

이 그림은 숫자 5로 보인다. 실제 레이블을 확인하면

```python
print (y[0])
```
이에 대한 결괏값이 5로 출력됨을 알 수 있다.

이번에는 이미지 샘플을 더 확인해보자.
```python
plt.figure(figsize=(9, 9))
for idx, image_data in enumerate(X[:100]):
    plt.subplot(10, 10, idx + 1)
    plot_digit(image_data)
plt.subplots_adjust(wspace=0, hspace=0)
save_fig("more_digits_plot", tight_layout=False)
plt.show()
```
이에 대한 결괏값은 다음과 같다.

![download](https://github.com/user-attachments/assets/8d8067ea-5fe7-4082-b7c5-0420ec82f41d)

**데이터 섞기는 모델 학습에서 매우 중요한 과정이다.** 데이터를 섞지 않으면 훈련 세트와 검증 세트에 특정 클래스(레이블)가 편향될 가능성이 있다. 예를 들어, MNIST 데이터셋에서 0-9 숫자의 샘플이 순차적으로 나열되어 있다면 초반 샘플에는 주로 0,1이 많고 후반에는 8,9가 몰려 있을 수 있다. 따라서 교차 검증에서 각 폴드에 모든 클래스가 골고루 포함되도록 데이터를 섞어 공정성을 확보해야 한다. 또한, 데이터를 섞지 않고 폴드를 나눈다면 특정 폴드에 어떤 클래스가 전혀 포함되어 있지 않아 모델이 학습할 기회를 갖지 못해 부정확한 결과를 낼 수 있다. 
***그러므로, 데이터(데이터셋)를 섞어 클래스 분포를 균일하게 만들고 훈련 안정성을 증가시켜야 한다.***

MNIST 데이터에서는 훈련 세트 (앞쪽 60000개 이미지)와 테스트 세트 (뒤쪽 10000개 이미지)로 구성되어 있다. 
```python
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
```

|용어|용도|
|---|---|
|훈련세트|모델을 학습시키기 위해 사용|
|테스트 세트|모델이 학습하지 않은 데이터로 성능 평가|

그러나 모든 데이터가 이렇게 나누어져 있는 것은 아니기에, 데이터 조사 전에 항상 테스트 세트를 만들고 따로 떼어놓아야 한다. 그리하여 모델이 새로운 데이터에 대해 얼마나 일반화할 수 있는지 평가 가능하도록 만들어야 한다.

## 3.2 이진 분류기 훈련
**이진 분류기 훈련은 True와 False, 0과1 등을 구분할 수 있는 분류기이다.** 분류 작업을 위해 타깃 벡터를 우선 만들고, 분류 모델을 선택하여 훈련을 시켜보려고 한다. **확률적 경사 하강법(SGD)은 이진 분류기를 학습시키는 데 사용되는 최적화 도구이다.**

다음 코드를 통해 살펴보자.
```python
y_train_5 = (y_train == '5')
y_test_5 = (y_test == '5')
from sklearn.linear_model import SGDClassifier
sgd_clf = SGDClassifier(random_state = 42)
sgd_clf.fit(X_train, y_train_5)
# 괄호 안의 첫 번째 인자는 모든 훈련 데이터의 입력(특징 데이터)를 의미한다. 두 번째 인자는 레이블 데이터로, 여기서는 숫자 5에 해당하는 샘플만을 골라내어 T/F로 구성된 이진 레이블 데이터이다.
# 모델은 X_train의 각 샘플을 보고 그것이 '5'인지 아닌지 (y_train_5)를 학습한다.
'''
![image](https://github.com/user-attachments/assets/784a1d66-7184-48ef-b293-cd06251279d7)

이제 이 모델을 사용하여 숫자 5의 이미지를 감지해보자.
```python
sgd_clf.predict([some_digit])
```
![image](https://github.com/user-attachments/assets/74ea1a55-5539-4a5d-ab96-81b198d5aef9)

분류기는 이 이미지가 5를 나타낸다고 추측하였다.

## 3.3 성능 측정
### 3.3.1 교차 검증을 사용한 정확도 측정
cross_val_score () 함수로 폴드가 3개인 k-폴드 교차 검증을 사용해 SGDClassifier 모델을 평가해보려고 한다.

k-폴드 교차 검증 : 훈련 세트를 k개의 폴드로 나누고, 평가를 위해 매번 다른 폴드를 떼어놓고 모델을 k번 훈련함
```python
from sklearn.model_selection import cross_val_score
cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring="accuracy")
```
이에 대한 결괏값은 0.90 이상이다.

가끔 교차 검증 과정을 더 많이 제어해야 할 때는 교차 검증 기능을 직접 구현하면 된다.
```python
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone

skfolds = StratifiedKFold(n_splits=3)  # 데이터셋이 미리 섞여 있지 않다면
                                       # shuffle=True를 추가하세요.
for train_index, test_index in skfolds.split(X_train, y_train_5):
    clone_clf = clone(sgd_clf)
    X_train_folds = X_train[train_index]
    y_train_folds = y_train_5[train_index]
    X_test_fold = X_train[test_index]
    y_test_fold = y_train_5[test_index]

    clone_clf.fit(X_train_folds, y_train_folds)
    y_pred = clone_clf.predict(X_test_fold)
    n_correct = sum(y_pred == y_test_fold)
    print(n_correct / len(y_pred))
```
이렇게 해도 결괏값이 95% 이상이 된다. 

이번에는 가장 많이 등장하는 클래스 (이 자료에서는 음성 클래스, 즉 '5 아님')로 분류하는 더미 분류기를 만들어 비교해보자.
```python
from sklearn.dummy import DummyClassifier

dummy_clf = DummyClassifier()
dummy_clf.fit(X_train, y_train_5)
print(any(dummy_clf.predict(X_train)))

cross_val_score(dummy_clf, X_train, y_train_5, cv=3, scoring="accuracy")
```
이 역시 결과가 90% 이상이 나온다.

위 과정은 분류기의 성능 측정 지표로 정확성을 지정한 것을 나타낸다. 그러나, 정확성을 지표로 사용하면 문제가 생긴다.

예를 들어보자. 특정 집단 중 대다수가 암에 걸리지 않은 환자이고, 소수가 암에 걸린 환자인 데이터가 존재한다고 가정한다. 그렇다면, 정확도를 기준으로 했을 때 대다수에 초점을 맞춘 예측값은 암에 걸린 환자를 반영하지 못하는 불균형이 생길 수 있다. 

그렇기에, **분류기의 성능을 평가하는 데 더 좋은 방법은 오차 행렬을 조사하는 것이다.**

### 3.3.2 오차 행렬
오차 행렬의 기본 아이디어는 모든 A/B 쌍에 대해 클래스 A의 샘플이 클래스 B로 분류된 횟수를 세는 것이다.\

예를 들어보자. 실제 레이블이 [5,0,0,5,0,5,0,5,5,0] 이고 예측 레이블이 [5,0,0,5,0,5,0,5,5,0]이라고 가정해보자.

이진 분류에는 (숫자 5 or not) 2개의 클래스가 있다. Positive Class (숫자 5), Negatie Class (숫자 5가 아님)

오차 행렬은 다음과 같이 구성된다. 

|실제/예측|숫자 5(P)|숫자 5 아님(N)|
|---|---|---|
|숫자 5(P)|True Positive|False Negative(FN)|
|숫자 5 아님(N)|False Positive|True Negative|

TP : 실제 숫자 5인데, 모델도 5로 예측한 경우 => TP = 3
FN : 실제 숫자 5인데, 모델이 5가 아니라고 예측한 경우 => FN = 1
FP : 실제 숫자 5가 아닌데, 모델이 5라고 예측한 경우 => FP = 1
TN : 실제 숫자 5가 아니고, 모델도 5가 아니라고 예측한 경우 => TN = 4

이를 통해 정확도, 정밀도, 재현율 등 성능 지표를 계산하는 것을 의미한다.

위의 예시처럼 오차 행렬을 만들려면 실제 타깃과 비교할 수 있도록 예측값을 만들어야 한다. cross_val_predict() 함수를 사용하여 예측을 만들어보자.

```python
from sklearn.model_selection import cross_val_predict
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_train_5, y_train_pred)
```
이에 대한 결괏값은 다음과 같다.

![image](https://github.com/user-attachments/assets/e5e86621-a967-4d9c-850d-80a4c30566e0)

오차 행렬의 행은 실제 클래스를, 열은 예측 클래스를 나타낸다. 이 행렬의 1행은 '5 아님' 이미지 (음성 클래스)에 대해 53892개를 '5 아님'으로 정확히 분류했고 (TN), 687개는 5라고 잘못 분류했다. (FP 또는 1종 오류) 두 번째 행은 5 이미지에 대해 1891개를 5 아님으로 잘못 분류했고 (FN 또는 2종 오류) 나머지 3230개를 정확히 5라고 분류했다. (TP)

완벽한 분류기라면 진짜 양성(TP)과 진짜 음성 (TN)만 가지고 있을 것이므로 오차 행렬의 주대각선만 0이 아닌 값이 된다.

```python
y_train_perfect_predictions = y_train_5  # 완벽한 분류기일 경우
confusion_matrix(y_train_5, y_train_perfect_predictions)
```
이에 대한 결괏값은 다음과 같다.

![image](https://github.com/user-attachments/assets/b5106812-46e0-4024-a8c1-351ffe64e171)

오차 행렬의 정보들 중 더 요약된 지표를 알아보자.

**정밀도 : 양성 예측의 정확도**
정밀도 = TP/TP+FP (TP : 진짜 양성의 수, FP : 거짓 양성의 수)

정밀도 100% 만드는 방법은 간단하다. 제일 확신이 높은 샘플에 대해 양성 예측을 하고 나머지는 모두 음성 예측을 하는 분류기를 만들면 된다. (의미 없음)
정밀도는 재현율이라는 또 다른 지표와 같이 사용하는 것이 일반적이다.
**재현율 : 분류기가 정확하게 감지한 양성 샘플의 비율 (=민감도, 진짜 양성 비율(TPR))**
재현율 = TP/TP+FN (FN : 거짓 음성의 수)


