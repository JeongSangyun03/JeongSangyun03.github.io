---
layout : post
title : 실무로 통하는 인과추론 CH5
categories : 쿠다ML심화
---
## CH5. 성향점수
이번 장에서는 성향점수 가중치를 이용하여 편향을 제거하는 방법을 살펴볼 것이다. (이진, 이산형 처치 있을 때 적합)


1. 문제 상황
- 목표: **관리자 교육(처치, T)** → **직원 참여도(결과, Y)** 인과효과 추정
- 문제: 교육 여부와 참여도에 동시에 영향을 주는 **공변량(X)** 존재 → 단순 비교 시 **편향 발생**

2. 공변량 조절의 의미
- 공변량을 모형에 포함해 **가짜 상관(비인과적 경로)** 제거
- 회귀모형 예시:
$  
\[
Y = \beta_0 + \beta_1 T + \beta_2 X + \epsilon
\]
$
- 여기서 $\(\beta_1\)$: 공변량 효과를 제거한 후 교육의 순수 효과

3. 계수 보정(Coefficient Adjustment)
- 공변량을 통제하면 $\(T\)$의 효과 계수($\$(\beta_1\$))$가 **보정된 효과**로 추정됨
- 이 과정을 흔히 **계수 보정**이라고 부름
- 다른 방법: 성향점수매칭, 층화, 가중치(IPW) 등도 가능하지만, 회귀모형에서의 조절이 가장 기본적임

**성향점수**

1. 정의
- 성향점수:
$$
e(X) = P(T=1 \mid X)
$$
공변량 $X$ 가 주어졌을 때 처치(교육)를 받을 확률.

- 조건부 독립성(CIA):
$$
(Y(0), Y(1)) \perp T \mid X
$$

<img width="400" height="150" alt="image" src="https://github.com/user-attachments/assets/5ebcdcfe-ef31-4933-a1c4-accbf7bc185d" />

2. 의미
- 공변량 $X$ 전체를 통제하는 대신, **$e(X)$** 하나로 요약해도 동일한 효과.  
- 즉, 성향점수는 **무작위 실험처럼 비교 가능**하게 해주는 도구.

3. “통제한다”의 실제 의미
- 성향점수 값 (예: $0.8$, $0.2$)을 **하나로 바꾸는 게 아님**.  
- 대신 분석에서 활용:
  - **매칭(Matching):** 비슷한 $e(X)$ 가진 처치군–통제군 비교  
  - **층화(Stratification):** $e(X)$ 구간별 층으로 나눠 비교  
  - **가중치(IPW):** $1/e(X)$ 또는 $1/(1-e(X))$ 등을 가중치로 부여해 집단 분포를 맞춤  

**성향점수 추정** : 실제 성향점수는 알 수 없는 이상적인 값이다. 현실에서는 처치 배정 메커니즘을 대부분 알 수 없으며, 실제 성향점수 e(x)를 추정값으로 대체해야 한다.

**성향점수와 직교화** 

| 구분 | OLS | 성향점수 |
|------|-------------------------------|---------------------------------------------|
| 목적 | 교란 변수 통제 후 처치 효과 추정 | 교란 변수 통제 후 처치 효과 추정 |
| 방법 | $X$를 회귀식에 직접 포함해 계수 보정 | $X$를 $e(X)$로 요약하여 매칭·가중치 등으로 균형화 |
| 결과 | $\beta_1$: 보정된 처치 효과 | ATT/ATE 추정치: 무작위화된 것처럼 비교 |

**성향점수 매칭**

e(X) = P(D=1|X) 계산 후, 처치군 개체(D=1)과 비처치군 개체 (D=0)을 **비슷한 성향점수**를 가진 쌍으로 매칭하여, 무작위 실험에서처럼 공변량이 비슷한 집단 간 비교를 가능하게 하는 방법

=> 대조군의 knn 모델을 통해 실험군의 짝을 찾고, 실험군의 knn 모델을 이용해 대조군의 짝을 찾는다. 각 실험 대상에 짝이 지어졌다면, 다음과 같이 ATE 추정 가능

**역확률 가중치**

성향점수를 활용하는 역확률 가중치 (IPW) : 처치의 역확률에 따라 데이터의 가중치를 재조정하여 해당 데이터에서 처치가 무작위 배정된 것처럼 보이게 할 수 있음.

성향점수가 높을수록(=처치받을 확률이 큰 집단) 처치군은 “덜 대표적”이므로 → 작은 가중치

성향점수가 낮을수록(=처치받을 확률이 작은 집단) 처치군은 “희귀한 케이스”라서 → 큰 가중치

이러한 성향점수를 이용해 **ATE** 구할 수 있음

**역확률 가중치의 분산**

추정의 불안정성: IPW는 편향을 줄여주지만, 분산이 너무 크면 신뢰구간이 넓어져서 “효과가 있다/없다” 결론을 내리기 힘듦.

Bias-Variance Tradeoff: IPW는 unbiased estimator로 알려져 있지만, 효율성(efficiency)이 떨어질 수 있음.

=> 큰 가중치 (희귀한 놈들) 가 적용되면 성향점수 추정량의 분산이 크게 증가함

**안정된 성향점수 가중치**

- 단순 IPW는 극단적 성향점수(0 또는 1에 가까움)에서 분산이 커짐.
- **안정화된 가중치(stabilized weight)** 사용:
  $
  w = \frac{P(T=t)}{P(T=t \mid X)}
  $
- 표본이 모집단에 더 가깝고 계산이 안정적임.

**유사 모집단**

- IPW 적용 후 다루는 건 실제 모집단이 아님.
- 처치 확률이 균등하게 보정된 **가상의 모집단(유사 모집단)**.
- 완전한 RCT는 아니지만 선택편향을 줄여줌.

**선택편향**

- **선택편향(selection bias)**: 공변량 차이 때문에 처치 여부가 달라지는 문제.
- 성향점수 가중치로 선택편향을 보정할 수 있음.
- **Horvitz–Thompson 추정량**:
  $
  ATE = \frac{1}{N} \sum_i \left[ \frac{Y_i T_i}{e(X_i)} - \frac{Y_i (1-T_i)}{1-e(X_i)} \right]
  $

**편향–분산 트레이드오프**

- 성향점수 → 교란 문제를 줄여서 **편향 ↓**.
- 하지만 극단적 확률 → 가중치 폭발 → **분산 ↑**.
- 따라서:
  - 편향 줄이면 분산 커질 수 있음.
  - 분산 줄이면 편향 커질 수 있음.
- 적절한 균형 필요.

**양수성 가정 (Positivity)**

- 모든 개체가 처치를 받을 확률이 **0과 1 사이**여야 함.
- 어떤 집단이 100% 처치 or 100% 대조군이면 효과 비교 불가.
- 위배되면 IPW 추정 불안정 → 분산 폭증 → ATE 추정 불가.

**디자인 vs 모델 기반 식별**

- **디자인 기반**: 데이터 수집 단계에서 편향을 줄임.  
  - 예: RCT, 층화, 성향점수 매칭, IPW  
- **모델 기반**: 분석 단계에서 모형 가정으로 보정.  
  - 예: 회귀모형, 인과모형  
- 차이:
  - 디자인 기반 → “실험처럼 보이게”  
  - 모델 기반 → “데이터로 수학적 보정”

**이중 강건 추정 (Doubly Robust Estimation)**

- 성향점수 모형 $e(X)$ + 결과모형 $m(X)$을 결합.
- 공식:
  $
  \hat{\mu}_{DR}(m,e) = \frac{1}{N} \sum_i \left[ m(X_i) + \frac{T_i}{e(X_i)} (Y_i - m(X_i)) \right]
  $
- 장점:
  - 성향점수 모형이 틀려도 결과모형이 맞으면 일관된 추정.
  - 결과모형이 틀려도 성향점수가 맞으면 일관된 추정.
  - 둘 다 맞으면 효율성 ↑.

**처치 모델링이 쉬운 경우**

- 처치 확률이 단순 → IPW만으로도 충분.
- 현실은 복잡 → DR 추정이 더 안정적.

**결과 모델링이 쉬운 경우**

- 결과모형이 단순한 경우 → 회귀모형이 더 적합.
- DR 추정은 두 가지를 결합해 안정성을 확보.

**연속형 처치에서의 일반화 성향점수 (GPS)**

- 이진 처치(0/1)만이 아니라, **연속형 처치**(금리, 약물 용량, 교육 시간 등)도 존재.
- 일반 성향점수 대신 **조건부 밀도 함수** 활용:
  $
  GPS = f(T \mid X)
  $
- 방법:
  1. 연속형 처치의 조건부 밀도 $f(T \mid X)$ 추정.
  2. 이를 기반으로 안정화된 가중치 생성.
  3. 회귀모형에 GPS 포함해 교란 보정.
- 활용: 금융(대출 금리 효과), 의학(약물 용량 효과), 교육(학습 시간 효과) 등.

## CH6. 이질적 처치효과

1. ATE → CATE
- ATE(평균 처치효과)는 전체 집단의 평균적인 효과만 제공함  
- CATE(조건부 평균 처치효과)는 특정 조건 X에서의 효과를 보여줌  
- 예시: 쿠폰 제공 시 전체 평균 매출은 +5%지만, 20대 고객은 +15%, 50대 고객은 0%  

2. 예측 vs 인과
- 예측 모델은 누가 Y가 큰지를 맞추는 데 초점  
- 인과추론은 처치 T가 Y에 주는 변화를 구하는 데 초점  

3. 회귀분석으로 CATE 추정
- 회귀식에 상호작용항을 넣어 조건별 효과를 추정  
- 매출 = α + βT + γX + δ(T×X) + 오차  
- 예시: 주말(X=1)일 때 쿠폰(T=1)의 효과가 평일과 다름을 δ로 포착  
- 공변량을 통제하지 않으면 왜곡된 추정 발생  

4. CATE 모델 평가
- 데이터를 훈련/테스트로 나누어 검증  
- “CATE가 크다고 예측된 집단”이 실제로도 큰 효과를 보이는지 확인  
- 처치군/대조군 불균형이 있을 때 머신러닝 기법이 더 정밀할 수 있음  

5. 분위수 분석과 반응곡선
- 예측된 CATE 값 기준으로 집단을 분위수(예: 5분위, 10분위)로 나눔  
- 각 집단별 실제 효과를 계산 후 곡선으로 표현 → 반응곡선  
- 예시: 상위 20% 고객은 쿠폰 효과 +10, 하위 20%는 +1  
- 좋은 모델이면 반응곡선이 우상향 패턴을 가짐  

6. 누적 효과 곡선과 누적 이득 곡선
- 누적 효과 곡선: 상위 집단부터 누적 처치효과를 계산해 그림  
- 좋은 모델이면 초반 곡선이 가파르게 상승  
- 누적 이득 곡선: 누적 표본 대비 성과를 나타내며 AUC로 요약 가능  
- 예시: AUC=0.8이면 모델이 무작위보다 훨씬 잘 구분함  

7. 목표 변환
- Y(1)−Y(0)을 직접 관찰할 수 없으므로 근사 목표 변수를 정의  
- 잔차(residual)나 성향점수를 활용해 모델이 개별 처치효과에 민감하게 학습되도록 함  
- 단순 Y 예측이 아니라 “처치에 민감한 사람”을 구분하도록 유도  

8. 예측모델과 CATE 정렬의 관계
- Y와 T의 관계가 단순할 때 Y 예측 모델도 CATE 정렬에 적합할 수 있음  
- 예: 할인율이 높을수록 구매량이 거의 선형 증가 → Y 예측 모델도 잘 작동  
- 한계수확체감 존재 시 단순 예측모델은 CATE 정렬에 실패할 수 있음  
- 예: 이미 매일 구매하는 고객은 추가 할인에 반응이 거의 없음 ㅋ 

9. CATE의 의사결정 활용
- 목적은 “누가 처치에 잘 반응하는가”를 찾아내어 자원을 집중하는 것  
- 예시: 모든 고객에게 쿠폰 제공 대신 반응이 큰 상위 30%에게만 제공  
- 정책에서도 동일하게 활용 가능: 복지를 전 국민이 아니라 효과가 큰 집단에 집중  
- 비용·수익 함수까지 고려해 최적 가격이나 정책 설계 가능  






