---
layout : post
title : 4주차
categories : ML 기초
---
# 쿠다 ML 기초 4주차
이번 주차에서는 앙상블 학습과 랜덤 포레스트에 대하여 공부한다.

일련의 예측기 (분류나 회귀 모델)로부터 예측을 수집하면 가장 좋은 모델 하나보다 더 좋은 예측을 얻을 수 있다. 이 일련의 예측기를 **앙상블**이라고 하며, 이러한 예측과정을 **앙상블 학습**이라고 한다.

앙상블 방법 중 하나의 예시 : 훈련 세트로부터 랜덤으로 각기 다른 서브셋을 만들어 일련의 결정 트리 분류기를 훈련 시킴. 개별 트리 예측을 모아 가장 많은 선택을 받은 클래스를 앙상블의 예측으로 삼음. 결정트리의 앙상블을 **랜덤 포레스트**라고 함

실제로 앙상블 방법을 사용하여 여러 괜찮은 예측기를 연결하여 더 좋은 예측기를 만든다.

## 7.1 투표 기반 분류기

![image](https://github.com/user-attachments/assets/29063c51-27c9-4562-a54b-8c4732e7eb11)

위와 같이 정확도가 80%인 분류기 여러 개를 훈련시켰다고 가정하자. 더 좋은 분류기를 만들 수 없을까?

이에 대한 간단한 방법은 각 분류기의 예측을 집계하는 것이다. 가장 많은 표를 얻은 클래스가 앙상블의 예측이 된다. 이러한 분류기를 **직접 투표 분류기**라고 한다.

![image](https://github.com/user-attachments/assets/83357205-cb3c-4ee5-87c1-8cf21d406ee5)

각 분류기가 **약한 학습기**일지라도 앙상블에 있는 약한 학습기가 충분하게 많고 다양하다면 앙상블은 **강한 학습기**가 될 수 있다. ***큰수의 법칙***을 생각한다면 연결지어 이해하기 쉬울 것이다.



