---
layout : post
title : 쿠다 ML 심화 2주차
categories : 쿠다 ML 심화
---
# 14. 합성곱 신경망을 사용한 컴퓨터 비전
합성곱 신경망 (CNN) : 이미지 검색 서비스, 자율 주행 자동차, 영상 자동 분류 시스템, 음성 인식, NLP 등에 사용

본 장에서는 **시각적인 애플리케이션**에 초점을 맞춤 → (CNN이 어디에서 왔는가. 구성요소는 무엇인가. 케라스로 사용하는 방법은 무엇인가.)

## 14.1 시각 피질 구조
시각 피질에 관한 연구 → **합성곱 신경망** 연구 

시각 피질에 관한 연구 중요 특징 : 

1. 시각 피질 내 많은 뉴런 : 작은 **국부 수용장** (시야의 일부 범위 안에 있는 시각 자극에 반응)
2. 동일한 수용장을 가진 뉴런 내에서도 다른 요소에 반응
3. 어떤 뉴런 : 큰 수용장을 가져 저수준 패턴 조합된 더 복잡한 패턴에 반응 (이웃한 저수준 뉴런의 출력에 기반한 고수준 뉴런)

**합성곱 신경망** 연구 : 

**LeNet-5 구조** 사용 (완전 연결 층 & 시그모이드 활성화 함수 포함 & **합성곱 층**, **플링 층** 포함)

## 14.2 합성곱 층
합성곱 층 : CNN의 가장 중요한 구성 요소

첫 번째 합성곱 층의 뉴런 : 합성곱 층 뉴런의 수용장 안에 있는 픽셀에만 연결

(☞네트워크가 첫 번째 은닉 층에서는 작은 저수준 특성에 집중. 후에 더 큰 고수준 특성으로 조합해 나감)

어떤 층 i행 j열에 있는 한 뉴런 : 이전층의 i에서 i + fh -1 까즤의 행 & j + fw - 1까지의 열에 있는 뉴런의 출력에 연결. (높이와 너비)

**제로 패딩** :높이와 너비를 이전 층과 같게 하기 위해 입력 주위에 0 추가하는 것

**스트라이드** : 한 수용장 & 다음 수용장 사이의 수평 또는 수직 방향 스텝 크기

스트라이드를 이용하여 차원 축소를 진행하고 계산 복잡도를 줄일 수 있음. (수용장 사이에 간격을 두어 큰 입력 층을 훨씬 작은 층에 연결)

(※ 스트라이드의 가로세로 크기가 동일할 수도 있고, 다를 수도 있다.)

## 14.2.1 필터
![image](https://github.com/user-attachments/assets/b2dd6380-4eab-46cb-a57f-126fa905afce)

이미지를 통해 이해해보자.

**필터** : (합성곱 커널 또는 커널이라고 불림). 이는 두 개의 가중치 세트. 

첫 번째 필터 : 가운데 흰 수직선(열이 1로 채워짐)과 그 외(열이 0으로 채워짐)가 있는 검은 사각형 (7*7 행렬 구성)

두 번째 필터 : 가운데 흰 수평선이 있는 검은 사각형

(※ 1의 특성을 가진 흰색 부분을 제외하면 수용장 안의 모든 것을 무시할 것)



