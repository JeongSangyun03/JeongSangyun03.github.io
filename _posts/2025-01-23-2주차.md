---
layout : post
title : 모델 훈련
---
# 4. 모델 훈련
이 장에서는 가장 간단한 모델인 선형 회귀와 비선형 데이터셋에서 훈련시킬 수 있는 조금 더 복잡한 모델인 다항회귀를 살펴보겠다.
***용어 정리***
**비선형 데이터셋 : 독립 변수(입력 특성)와 종속 변수(목표값) 간의 관계가 단순한 직선(선형 함수)으로 설명되지 않는 데이터셋**
**과대 적합 : 과대적합이란 머신러닝 모델이 훈련 데이터를 너무 잘 학습한 나머지, 테스트 데이터나 새로운 데이터에 대해 일반화 성능이 떨어지는 현상을 말함. 즉, 모델이 훈련 데이터의 잡음(noise)이나 세부적인 패턴까지 과도하게 학습하여, 실제로 중요한 일반적인 패턴을 제대로 잡아내지 못하는 상황.**

## 4.1 선형 회귀
선형 모델은 입력 특성의 가중치 합과 편향이라는 상수를 더해 예측을 만든다.
![Image-1 (1)](https://github.com/user-attachments/assets/545ed7b1-1c1c-4a10-9f17-a01072d207bd)
이는 벡터 형태로 다음과 같이 더 간단하게 쓸 수 있다.
![Image-1 (2)](https://github.com/user-attachments/assets/9d89c85a-a1df-4483-a13e-9c319aa92320)
이것이 선형 회귀 모델이다. 이를 훈련시킨다는 것은 모델이 훈련 세트에 가장 잘 맞도록 모델 파라미터를 설정하는 것이다. 이를 위해 먼저 모델이 훈련 데이터에 얼마나 잘 드어맞는지 측정해야 한다.
성능 측정 지표를 사용하자. 가장 널리 사용되는 성능 측정 지표는 평균 제곱근 오차(RMSE)이다. RMSE를 최소화하는 ∂를 찾아야 한다.
(실제로는 평균 제곱 오차(MSE)를 최소화하는 것이 같은 결과를 내면서 더 간단하다.)
![Image-1 (3)](https://github.com/user-attachments/assets/05193959-cdd3-42c7-afef-d851f0ec6358)
여기서 X는 데이터셋에 있는 모든 샘플의 모든 특성값(레이블 제외)을 포함하는 행렬이다. h는 시스템의 예측 함수이며 가설이라고도 한다.

### 4.1.1 정규 방정식
비용 함수를 최소화하는 ∂값을 찾기 위한 해석적인 방법이 있다. 여기서 이러한 결과를 바로 얻을 수 있는 수학 공식을 정규 방정식이라고 한다.
![Image-1 (4)](https://github.com/user-attachments/assets/bb41bc8c-7c05-49ea-be01-74509c232c25)
