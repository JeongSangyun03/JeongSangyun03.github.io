---
layout : posts
title : "쿠다 ML 기초 4주차"
categories : "쿠다 ML 기초"
---
# 16. RNN과 어텐션을 사용한 자연어 처리

## 16.1 Char-RNN으로 셰익스피어 문체 생성하기
Char-RNN을 훈련하여 문장에서 다음 글자를 예측하는 방법 : 한 번에 한 글자씩 새로운 텍스트를 생성

### 16.1.1 데이터셋 생성하기
셰익스피어 문체 생성 방법
1. 안드레이 카르파시의 Char-RNN 프로젝트 셰익스피어 작품 다운로드
2. 셰익스피어 텍스트를 문자 단위로 벡터화 (split="character" 사용하여 문자 단위로 쪼갠 후 숫자로 바꿈)
3. RNN 학습을 위해 입력 시퀀스와 타깃 시퀀스로 나누는 데이터셋을 생성 (타깃 시퀀스로 다음 글자 예측하도록 구성)
4. 훈련 세트, 검증 세트, 테스트 세트 생성

### 16.1.2 Char-RNN 모델 만들고 훈련하기
언어 모델링 → 데이터셋 多 : 단순한 RNN 이상의 것 필요 (단순 RNN은 오래된 정보 기억 ↓) 

예제에서는 128개의 유닛으로 구성된 하나의 GRU층을 가진 모델을 구축하고 훈련 (정보를 잘 기억하며 효율적인 학습 가능)

```python
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),  # ❶
    tf.keras.layers.GRU(128, return_sequences=True),
    tf.keras.layers.Dense(n_tokens, activation="softmax")          # ❷
])

model.compile(
    loss="sparse_categorical_crossentropy",
    optimizer="nadam",
    metrics=["accuracy"]
)

model_ckpt = tf.keras.callbacks.ModelCheckpoint(
    "my_shakespeare_model", monitor="val_accuracy", save_best_only=True  # ❸
)

history = model.fit(
    train_set,
    validation_data=valid_set,
    epochs=10,
    callbacks=[model_ckpt]
)
```
이미 전처리 된 (벡터화된) 숫자 시퀀스만 입력으로 받기에, TextVectorization을 포함한 최종 모델은 원본 텍스트 → 문자 단위 벡터화 → 문맥 이해 → 다음 글자 예측까지 한 번에 처리

### 16.1.3 가짜 셰익스피어 텍스트 생성하기
**텍스트 생성 방식**

Char-RNN 모델로 다음 글자를 하나씩 예측하여 텍스트를 생성

단순히 확률이 가장 높은 글자만 고르면 반복이 많아짐 → greedy decoding

해결 : tf.random.categorical()로 확률 기반 랜덤 샘플링 수행

온도(Temperature) : 확률 분포를 조절하는 값 (샘플 다양성 조절)

|온도 ↓|정확도 ↑|창의성 ↓|
|---|---|---|
|온도 ↑|창의성 ↑|정확도 ↓|

***온도에 따라 생성되는 문장 스타일이 크게 달라짐***

**한계점 및 개선 방향**

단순 RNN 구조는 긴 문장 처리에 약함

beam search, nucleus sampling 등으로 개선 가능

더 깊거나 넓은 GRU, LSTM 사용 시 성능 향상 가능 : 매우 긴 시퀀스 처리 불가 → **상태가 있는 RNN 사용**

### 16.1.4 상태가 있는 RNN
**상태가 있다? : 뭘 기억하고 있다.**

상태가 있는 RNN : 시퀀스를 짧게 자르며 처리한 훈련 배치의 마지막 상태를 다음 훈련 배치의 초기 상태로 사용 → 긴 문맥을 기억하며 학습할 수 있음 (복습은 짧게 하지만, 이야기의 맥은 이어지고 있다.)

1. 순차적이고 겹치지 않는 입력 시퀀스 생성
2. 배치 크기를 줄이는 등 조정하여 하나의 시퀀스가 연속적으로 이어지게 만듦
3. 에포크마다 상태 초기화 (새로운 문장을 처음부터 학습하기 위해)
4. 모델 훈련

## 16.2 감성 분석





