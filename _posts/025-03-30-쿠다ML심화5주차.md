![image](https://github.com/user-attachments/assets/8657fad2-e30b-457e-aefa-7a07af99fb98)---
layout : post
title : 쿠다 ML 심화 5주차
categories : 쿠다 ML 심화
---
# 5. 사이파이를 사용한 기본 확률 및 통계 분석

## 5.1 사이파이로 데이터와 확률 간 관계 탐색하기
scipy (scientific python) → 데이터의 임의성 평가에 유용

사이파이로 동전이 16번 이상 같은 면으로 떨어질 확률 구하기
```python
from scipy import stats

num_heads = 16       # 관측된 앞면 횟수
num_flips = 20       # 총 던진 횟수
prob_head = 0.5      # 앞면이 나올 확률 (공정한 동전)
prob = stats.binom_test (num_heads, num_flips, prob_head)
```
정확하게 앞면 16개가 관측될 확률 구하기 → PMF (확률질량함수 사용)
```python
prob_16_heads = stats.binom.pmf(num_heads, num_flips, prob_head)
```
여러 상황에서 각 상황에 대한 확률 동시에 구하기
```python
probabilities = stats.binom.pmf([4,16], num_flips, prob_head)
assert probabilities.tolist() == [prob_16_heads] * 2
```
range() 함수를 이용하여 앞면이 0번~20번 나올 각각의 확률을 전부 계산하기
```python
interval_all_counts = range(21)
probabilities = stats.binom.pmf(interval_all_counts, num_flips, prob_head)
total_prob = probabilities.sum()
```
total_prob = 1이 나와야 한다.

동전 뒤집기 20번에 대한 이항 분포도 그리기
```python
import matplotlib.pyplot as plt
plt.plot (interval_all)counts, probabilities)
plt.xlabel("동전 앞면의 등장 횟수")
plt.ylabel ("확률")
plt.show()
```
## 5.2 중심성의 척도로서 평균
중앙값 : 데이터를 크기 순으로 정렬했을 때, 정확히 가운데 위치한 값

중앙값이 특정 데이터와 떨어져 있다면? : 페널티를 부여하여 중심점 이동 (페널티가 가장 낮은 중심 찾기)

페널티가 가장 낮은 중심 : 전체 측정 데이터를 균등하게 분할 〓 중심성을 나타내는 좋은 척도

중복값이 존재하는 상황에서 가중된 평균 계산 시 평균 얻는 속도 ↑ (가중치 취급)

### 5.2.1 확률 분포의 평균 구하기
np.average () 메소드의 가중치 매개변수에 확률 배열 입력 → 평균 계산

분포의 평균 : 중심성을 나타내는 훌륭한 척도

### 5.3 흩어진 정도를 측정하는 분산
흩어짐 정도 ↓ : 데이터에 대한 예측 가능성 ↑

제곱합 (sum of squares) : 평균에서 거리의 제곱합 → 페널티 계산 가능 & 흩어진 정도 측정 가능

분산 : 제곱합 (변량 - 평균의) / 측정 배열 크기

np.var() 함수 호출하여 분산을 사용할 수 있음

### 5.3.1 확률 분포의 분산 구하기
표준편차 : 분산의 제곱근

np.std() 함수로 계산 가능

평균과 표준편차의 역할
1. 수치형 데이터 비교 가능 : 두 데이터 간 차이 정량화 가능
2. 확률 분포 비교 가능 : 분포의 평균과 표준편차 비교하여 두 분포 간 차이 요약 가능
3. 수치형 데이터셋과 확률 분포 비교 가능 : 분포와 데이터셋에 대해 중심성과 흩어진 정도를 나란히 배치하여 확인 가능

## 5.4 요약
확률 질량 함수 : 입력된 정수 값을 발생 확률에 매핑

이항 분포에 대한 확률 질량 함수 : stats.binom.pmf 호출하여 생성 가능

평균 : 데이터셋의 중심성 나타내는 좋은 척도

데이터셋에 대한 제곱합 최소화 & 데이터셋 크기로 데이터셋 값의 합 나누어 가중되지 않은 평균 계산 가능

분산 : 데이터셋의 흩어진 정도 나타내는 좋은 척도 : 평균에서 데이터가 떨어진 거리의 제곱 평균

표준편차 : 분산의 대안 척도 (단위 그대로)

# 6. 사이파이와 중심 극한 정리로 예측하기
사이파이 계산 능력을 활용하여 중심 극한 정리를 살펴보고, 이를 이용하여 제한된 데이터로 예측하는 방법을 살펴보자.
## 6.1 사이파이로 정규 분포 다루기
히스토그램의 평균 및 표준편차 계산
```python
mean_normal = np.average (bin_edges[:-1], weights = likelihoods)
var_normal = weighted_variance (bin_edges[:-1], likelihoods)
std_normal = var_normal**0.5
```
![image](https://github.com/user-attachments/assets/16b16558-dc30-44ec-869e-cbec09b1f7b9)

가장 높은 지점의 좌표로 평균 및 표준 편차 계산
```python
import math
peak_x_value = bin_edges[likelihoods.argmax()]
peak_y_value = likelihoods.max()
std_from _peak = (peak_y_value*(2*math.pi)**0.5) ** -1
```
평균과 표준편차는 stats.norm.fit(sample_means) 호출하여 간단히 계산 가능 (두 값 평균과 표준편차 반환)

### 6.1.1 샘플링된 정규 분포 곡선 두 개 비교하기
표본 크기가 다른 정규 분포 곡선 두 개 그리기
```python
np.random.seed(0)
new_sample_size = 40000
new_head_counts = np.random.binomial(new_sample_size, 0.5, 100000)
new_mean, new_std = stats.norm.fit(new_head_counts / new_sample_size)
new_likelihoods = stats.norm.pdf(bin_edges, new_mean, new_std)
```
표본 수가 증가함 → 분산 및 표준편차 감소 → 신뢰 구간 감소

신뢰구간 : 실제 확률을 포함한 가능한 값 범위

## 6.2 무작위 샘플링으로 모집단의 평균 및 분산 결정하기
주제: 전체 인구를 조사하지 않고도 일부 샘플만으로 평균과 분산을 추정할 수 있을까?

전체 인구: 5만 명 (나이 1~85세 무작위 생성)

목표: 모집단 평균 & 분산 추정

방법: 무작위 샘플링

모집단 평균: population.mean()

모집단 분산: population.var()

샘플링: 10명을 무작위 추출 → 평균 계산

이 과정을 100번 반복하여 평균들의 분포 확인

📌 정확한 전체 평균과의 차이도 계산 가능

샘플 평균들의 히스토그램 → 정규분포 형태

샘플 평균의 평균 ≒ 모집단 평균

실제 오차: 약 2% 이내

📌 중심극한정리 적용 가능!
(작은 샘플도 반복하면 평균은 신뢰도 높음)

분산 추정 공식:

Estimated Variance = 표준편차 2 × 샘플 크기



실제 분산과의 오차: 1.3% 이내

✅ 결론: 작은 샘플로도 인구의 특성을 꽤 정확히 추정 가능

## 6.3 평균과 분산을 이용하여 예측하기
예제 : 만 선생님의 반 성적 예측 

매년 정확히 20명의 학생을 가르친다고 가정하자. 

가정: 매년 정확히 20명씩 가르쳤다고 가정하며, 전체 성적은 평가 시험(0~100점) 기준으로 기록됨

2️⃣ 문제 정의

질문: 만 선생님은 실제로 평균적으로 다른 반보다 성적이 우수했을까?

성적 데이터는 학생 단위가 아닌 전체 성적 분포만 주어짐

→ 평균(population_mean) = 84, 분산(population_variance) = 25

3️⃣ 예측 모델 세우기: 평균과 분산만으로 추정!

학생 20명을 무작위로 뽑아 평균 점수를 구했을 때,

그 평균이 90점 이상일 확률은?

만 선생님이 가르친 반에서 그런 일이 일어났을 가능성은?

여기서 표준편차는 5, SEM (표본 평균의 표준 오차) 는 5/root(20) = 1.12

4️⃣ 정규분포 기반 확률 계산
평균이 84이고, 표준 오차가 1.12인 정규분포에서,

![image](https://github.com/user-attachments/assets/7ccbcbe4-1de8-4d42-9f0c-f1a0e63884ff)

 ≥90)=stats.norm.sf(90,84,1.12)
 
결과: 약 4.13e-08 (0.0000000413)

→ 만 선생님의 반이 평균 90점을 넘겼을 확률은 극히 낮음

5️⃣ 통계적 시사점

정규분포 곡선의 절반(평균 초과 영역)은 면적 0.5 (50%)

직접 적분으로 확인한 평균 초과 영역 면적은 약 0.500000000001924

→ 이론적으로 잘 맞음4

결론: 단순히 높은 성적을 보았다고 해서, 전체적으로 우수한 성과라 단정할 수 없다

평균과 분산만 알아도 정규분포 기반으로 정확한 확률 계산이 가능

# 7. 통계적 가설 검정

표본 평균과 모집단 평균 차이 평가하기 – p값으로 판단하자! ("우연히 이런 결과가 나올 확률은 얼마나 될까?")

1️⃣ 시나리오: 사우스다코타 학급의 높은 성적

노스다코타 주 전체 5학년의 평균 시험 성적은 80점, 분산은 100점으로 알려져 있음.

그런데 사우스다코타의 한 학급(18명)이 평균 84점을 기록했다? → 이 성적이 정말로 우수한 교육의 결과인지, 아니면 우연히 발생한 것인지 통계적으로 검정해보자.

2️⃣ 가설 수립

귀무 가설: 사우스다코타 학급의 성적은 노스다코타 전체와 차이가 없다 (우연한 차이일 뿐)

대립 가설: 사우스다코타 학급은 통계적으로 유의미하게 높은 성적을 보인다

3️⃣ 기본 세팅

모집단 평균 μ = 80

모집단 분산 σ² = 100

표본 크기 n = 18

표본 평균 X̄ = 84

→ 표본 평균의 표준 오차 (SEM):

 ≈2.36
 
4️⃣ 평균 84 이상일 확률 (p값)
```python
prob_high_grade = stats.norm.sf(84, 80, sem)
# 결과: p = 0.0448, 즉 4.48% 확률
```
의미: 정말로 차이가 없다면 이 정도로 높은 평균은 4.48% 확률로밖에 안 나옴

5️⃣ 양측 검정 (극단적 차이까지 포함)
```python
p_value = stats.norm.sf(84, 80, sem) * 2
# p값 = 0.0897 (8.97%)
```
해석: 통계학 기준인 5% 유의수준보다 높음 → 유의미한 차이라고 보기 어렵다, 우연일 가능성이 있음

6️⃣ p값은 얼마나 민감할까? 평균이 85라면?
```python
compute_p_value(85, 80, sem)
# p값 = 0.0834
```
평균이 1점 올라가도 p값은 약간만 감소 → 여전히 유의하지 않음

7️⃣ 임계값을 낮춰보면?

예: p < 0.001이라는 매우 엄격한 기준을 설정한다면?

평균 88점일 때 p값을 계산

결과: p = 0.000688 → 평균이 88점 이상이어야만, p < 0.001 조건을 만족함

평균 성적이 84점일 경우, 모집단 평균과 유의한 차이로 보기 어려움

평균이 88점 이상일 때에만 극단적 차이(p < 0.001) 로 간주 가능

p값은 단순한 기준이지만, **1종 오류(잘못된 결론)**와 2종 오류(진짜 차이 놓침) 사이의 균형이 중요함

지나치게 낮은 유의수준을 고르면 실제로 의미 있는 차이도 놓칠 수 있음

(p값이 작다 → 드물게 나타난다.)

(p값이 크다 → 우연일 가능성 높다.)

## 7.3 부트스트랩: 모집단 분산 모를 때 가설 테스트
📌 문제 상황

어떤 물고기 수족관의 평균 몸길이가 27cm로 추정됨.

하지만 전체 물고기의 모집단 평균과 분산을 알 수 없음.

이럴 땐 표본 평균만으로도 극단적인 값을 얻을 확률을 계산할 수 있을까?

🧪 해결 방법: 부트스트랩(bootstrap)

복원 추출로 여러 번 표본을 만들고, 그 평균들을 분석해서 분포를 예측하는 방식

🔁 절차 요약

실제 물고기 길이 20개를 샘플링하여 리스트 생성

복원 추출로 20마리를 다시 뽑아 평균 계산 → 이를 수천 번 반복

표본 평균들의 분포를 히스토그램으로 시각화

이 분포를 통해 극단적 평균이 나올 확률(p값) 추정 가능

📈 예시 분석 결과

평균 = 약 27cm

표본 평균 분포는 정규분포가 아님 → 약간 비대칭

특정 평균(예: 37cm 이상, 또는 17cm 이하)이 나올 확률은?

```python
prob_extreme = sf(37) + cdf(17)
```
→ 계산 결과: p ≈ 0.10 (10%)

→ 즉, 37 이상 또는 17 이하의 극단적 평균이 나올 확률은 약 10%

✅ p값 계산 방법 2가지

|접근법|설명|예시|
|---|---|---|
|누적함수 방식|생존함수(sf), 누적분포함수(cdf) 이용해 꼬리 확률 계산	|sf(37) + cdf(17)|
|직접계산 방식|37보다 크거나 17보다 작은 평균이 나온 횟수를 셈||

```python
number_extreme / len(sample_means)
```
→ 본 예제에서는 p ≈ 0.10

💡 핵심 포인트

부트스트랩은 모집단의 분산을 모를 때 사용 가능한 강력한 도구

히스토그램 기반 분포를 만들고, 직접 계산으로 통계적 유의성 평가 가능

정규분포 가정이 필요 없음 → 비대칭인 데이터에도 사용 가능

## 7.4 순열 테스트

✅ 문제 상황

우리 수족관의 물고기 길이 평균: 약 27cm

이웃 수족관의 물고기 10마리 평균: 46cm

두 평균 간 차이는 약 19cm → 통계적으로 유의한 차이일까?

🔍 제한 조건

모집단 평균이나 분산을 모를 때 사용할 수 있는 검정 방법 필요

두 표본 간 차이를 비교하고자 할 때 순열 테스트가 유용

🧠 순열 테스트란?

두 표본을 하나의 그룹으로 합친 뒤, 무작위로 재구성하여 평균 차이를 계산하고

실제 평균 차이가 극단적인지 판단하는 비모수적 검정 방법

🧩 순열 테스트 절차

두 그룹의 데이터를 하나로 통합 (np.hstack)

전체 데이터를 무작위로 셔플 (np.random.shuffle)

앞의 20개와 뒤의 10개를 두 그룹으로 나누어 평균 차이 계산

이 과정을 수천 번 반복하여 ‘평균 차이 분포’를 시뮬레이션

실제 평균 차이(19cm 이상)가 발생할 확률(p값)을 계산

🧾 실험 결과 요약

3만 번 반복 → 평균 차이 분포 히스토그램 생성

실제 평균 차이 19cm 이상이 나올 확률:

p-value≈0.04

→ 이는 유의수준 0.05보다 작음

→ 따라서 두 수족관 물고기는 통계적으로 다른 집단에서 나왔다고 판단 가능!

💡 핵심 포인트 요약

|항목|내용|
|---|---|
|모집단 분산 모를 때|평균 차이만으로 판단 불가|
순열 테스트 사용|두 집단 통합 후 무작위 셔플 & 평균 차이 계산 반복|
|장점|정규분포, 분산 가정 없음. 데이터만 있으면 검정 가능|
|적용 예시|광고 클릭률, 실험군 비교, 사용자 반응 분석 등|


