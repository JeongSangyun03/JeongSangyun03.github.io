---
layout : post
title : 쿠다 ML 심화 5주차
categories : 쿠다 ML 심화
---
# 5. 사이파이를 사용한 기본 확률 및 통계 분석

## 5.1 사이파이로 데이터와 확률 간 관계 탐색하기
scipy (scientific python) → 데이터의 임의성 평가에 유용

사이파이로 동전이 16번 이상 같은 면으로 떨어질 확률 구하기
```python
from scipy import stats

num_heads = 16       # 관측된 앞면 횟수
num_flips = 20       # 총 던진 횟수
prob_head = 0.5      # 앞면이 나올 확률 (공정한 동전)
prob = stats.binom_test (num_heads, num_flips, prob_head)
```
정확하게 앞면 16개가 관측될 확률 구하기 → PMF (확률질량함수 사용)
```python
prob_16_heads = stats.binom.pmf(num_heads, num_flips, prob_head)
```
여러 상황에서 각 상황에 대한 확률 동시에 구하기
```python
probabilities = stats.binom.pmf([4,16], num_flips, prob_head)
assert probabilities.tolist() == [prob_16_heads] * 2
```
range() 함수를 이용하여 앞면이 0번~20번 나올 각각의 확률을 전부 계산하기
```python
interval_all_counts = range(21)
probabilities = stats.binom.pmf(interval_all_counts, num_flips, prob_head)
total_prob = probabilities.sum()
```
total_prob = 1이 나와야 한다.

동전 뒤집기 20번에 대한 이항 분포도 그리기
```python
import matplotlib.pyplot as plt
plt.plot (interval_all)counts, probabilities)
plt.xlabel("동전 앞면의 등장 횟수")
plt.ylabel ("확률")
plt.show()
```
## 5.2 중심성의 척도로서 평균
중앙값 : 데이터를 크기 순으로 정렬했을 때, 정확히 가운데 위치한 값

중앙값이 특정 데이터와 떨어져 있다면? : 페널티를 부여하여 중심점 이동 (페널티가 가장 낮은 중심 찾기)

페널티가 가장 낮은 중심 : 전체 측정 데이터를 균등하게 분할 〓 중심성을 나타내는 좋은 척도

중복값이 존재하는 상황에서 가중된 평균 계산 시 평균 얻는 속도 ↑ (가중치 취급)

### 5.2.1 확률 분포의 평균 구하기
np.average () 메소드의 가중치 매개변수에 확률 배열 입력 → 평균 계산

분포의 평균 : 중심성을 나타내는 훌륭한 척도

### 5.3 흩어진 정도를 측정하는 분산
흩어짐 정도 ↓ : 데이터에 대한 예측 가능성 ↑

제곱합 (sum of squares) : 평균에서 거리의 제곱합 → 페널티 계산 가능 & 흩어진 정도 측정 가능

분산 : 제곱합 (변량 - 평균의) / 측정 배열 크기

np.var() 함수 호출하여 분산을 사용할 수 있음

### 5.3.1 확률 분포의 분산 구하기
표준편차 : 분산의 제곱근

np.std() 함수로 계산 가능

평균과 표준편차의 역할
1. 수치형 데이터 비교 가능 : 두 데이터 간 차이 정량화 가능
2. 확률 분포 비교 가능 : 분포의 평균과 표준편차 비교하여 두 분포 간 차이 요약 가능
3. 수치형 데이터셋과 확률 분포 비교 가능 : 분포와 데이터셋에 대해 중심성과 흩어진 정도를 나란히 배치하여 확인 가능

## 5.4 요약
확률 질량 함수 : 입력된 정수 값을 발생 확률에 매핑

이항 분포에 대한 확률 질량 함수 : stats.binom.pmf 호출하여 생성 가능

평균 : 데이터셋의 중심성 나타내는 좋은 척도

데이터셋에 대한 제곱합 최소화 & 데이터셋 크기로 데이터셋 값의 합 나누어 가중되지 않은 평균 계산 가능

분산 : 데이터셋의 흩어진 정도 나타내는 좋은 척도 : 평균에서 데이터가 떨어진 거리의 제곱 평균

표준편차 : 분산의 대안 척도 (단위 그대로)

# 6. 사이파이와 중심 극한 정리로 예측하기
사이파이 계산 능력을 활용하여 중심 극한 정리를 살펴보고, 이를 이용하여 제한된 데이터로 예측하는 방법을 살펴보자.
## 6.1 사이파이로 정규 분포 다루기
히스토그램의 평균 및 표준편차 계산
```python
mean_normal = np.average (bin_edges[:-1], weights = likelihoods)
var_normal = weighted_variance (bin_edges[:-1], likelihoods)
std_normal = var_normal**0.5
```
![image](https://github.com/user-attachments/assets/16b16558-dc30-44ec-869e-cbec09b1f7b9)

가장 높은 지점의 좌표로 평균 및 표준 편차 계산
```python
import math
peak_x_value = bin_edges[likelihoods.argmax()]
peak_y_value = likelihoods.max()
std_from _peak = (peak_y_value*(2*math.pi)**0.5) ** -1
```
평균과 표준편차는 stats.norm.fit(sample_means) 호출하여 간단히 계산 가능 (두 값 평균과 표준편차 반환)

### 6.1.1 샘플링된 정규 분포 곡선 두 개 비교하기
표본 크기가 다른 정규 분포 곡선 두 개 그리기
```python
np.random.seed(0)
new_sample_size = 40000
new_head_counts = np.random.binomial(new_sample_size, 0.5, 100000)
new_mean, new_std = stats.norm.fit(new_head_counts / new_sample_size)
new_likelihoods = stats.norm.pdf(bin_edges, new_mean, new_std)
```
표본 수가 증가함 → 분산 및 표준편차 감소 → 신뢰 구간 감소

신뢰구간 : 실제 확률을 포함한 가능한 값 범위

## 6.2 무작위 샘플링으로 모집단의 평균 및 분산 결정하기
주제: 전체 인구를 조사하지 않고도 일부 샘플만으로 평균과 분산을 추정할 수 있을까?

전체 인구: 5만 명 (나이 1~85세 무작위 생성)

목표: 모집단 평균 & 분산 추정

방법: 무작위 샘플링

모집단 평균: population.mean()

모집단 분산: population.var()

샘플링: 10명을 무작위 추출 → 평균 계산

이 과정을 100번 반복하여 평균들의 분포 확인

📌 정확한 전체 평균과의 차이도 계산 가능

샘플 평균들의 히스토그램 → 정규분포 형태

샘플 평균의 평균 ≒ 모집단 평균

실제 오차: 약 2% 이내

📌 중심극한정리 적용 가능!
(작은 샘플도 반복하면 평균은 신뢰도 높음)

분산 추정 공식:

Estimated Variance = 표준편차 2 × 샘플 크기

실제 분산과의 오차: 1.3% 이내

✅ 결론: 작은 샘플로도 인구의 특성을 꽤 정확히 추정 가능

